###### MAPREDUCE HADOOP ASSIGNMENT 1 #######

# all codes for different question are submitted separetly
# code 1 for question 1: Find out the count of each word in the ‘Shakespeare.txt’ dataset in the ‘Shakespeare.rar’
# code 2 for question 2: Find out the count of each word using two reducers only
# code 3 for question 3: Find out the most commonly used words (Words with the count over 100 are considered common)

# upload shakepeare file in hdfs 
hdfs dfs -put Shakespeare.txt input/

# to list all jar files and make sure it is present
ls -lrt hadoop

# to execute the mapreduce (.jar) program
hadoop jar wordcount1.jar WordCount1 input/Shakespeare.txt output/Shakespeare1
hadoop jar wordcount2.jar WordCount1 input/Shakespeare.txt output/Shakespeare2
hadoop jar wordcount3.jar WordCount1 input/Shakespeare.txt output/Shakespeare3

# to list output from directory output
hdfs dfs -ls output/Shakespeare1
hdfs dfs -ls output/Shakespeare2
hdfs dfs -ls output/Shakespeare3
